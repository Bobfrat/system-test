{
 "metadata": {
  "name": "",
  "signature": "sha256:2f088ebb7b7fa4c3dd0e28dc56d31abd3965ab6734b3e82ffb5ef5ff7e3a13be"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from utilities import css_styles\n",
      "css_styles()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "\n",
        "        <style>\n",
        "        .info {\n",
        "            background-color: #fcf8e3; border-color: #faebcc; border-left: 5px solid #8a6d3b; padding: 0.5em; color: #8a6d3b;\n",
        "        }\n",
        "        .success {\n",
        "            background-color: #d9edf7; border-color: #bce8f1; border-left: 5px solid #31708f; padding: 0.5em; color: #31708f;\n",
        "        }\n",
        "        .error {\n",
        "            background-color: #f2dede; border-color: #ebccd1; border-left: 5px solid #a94442; padding: 0.5em; color: #a94442;\n",
        "        }\n",
        "        .warning {\n",
        "            background-color: #fcf8e3; border-color: #faebcc; border-left: 5px solid #8a6d3b; padding: 0.5em; color: #8a6d3b;\n",
        "        }\n",
        "        </style>\n",
        "    "
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<IPython.core.display.HTML at 0x2fb3310>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# IOOS System Test - Theme 3 - Scenario A - [Description](https://github.com/ioos/system-test/wiki/Development-of-Test-Themes#scenario-3a-assessing-seabird-vulnerability-in-the-bering-sea)\n",
      "\n",
      "## Assessing Seabird Vulnerability in the Bering Sea\n",
      "\n",
      "## Questions\n",
      "1. Can we discover, access, and overlay Important Bird Area polygons (and therefore other similar layers for additional important resource areas) on modeled datasets in the Bering Sea?\n",
      "3. Is metadata for projected climate data layers and Important Bird Area polygons sufficient to determine a subset of polygons desired by a query?\n",
      "4. Can a simple set statistics (e.g., mean and standard deviation) be derived from multiple variables in each of the six models to derive the forecast variability of climate conditions through time, through the end of the model runs (2003-2040)?\n",
      "5. Can we create a standardized matrix or other display method for output variables that allow resource experts to easily assess projected changes in climate variables, within given ranges of time, and compare projected changes across multiple coupled oceanographic and climate models?\n",
      "6. Can we develop a set of process-specific guidelines and a standardized set of outputs for a tool that would allow researchers to address a diversity of resource management questions relative to projected changes in climate for specific zones of interest?\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Q1 - Can we discover, access, and overlay Important Bird Area polygons (and therefore other similar layers for additional important resource areas) on modeled datasets in the Bering Sea?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"error\"><strong>Discovery is not possible</strong> - No Important Bird Area polygons are not discoverable at this time.  They are, however, available in an GeoServer known to us.  This should be fixed.  The WFS service should be added to a queryable CSW.</div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### Load 'known' WFS endpoint with Important Bird Area polygons"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from owslib.wfs import WebFeatureService\n",
      "known_wfs = \"http://solo.axiomalaska.com/geoserver/audubon/ows\"\n",
      "wfs = WebFeatureService(known_wfs, version='1.0.0')\n",
      "print sorted(wfs.contents.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['audubon:audubon_all_seafloorsubstrate_project', 'audubon:audubon_beardedseal_polys', 'audubon:audubon_beluga_lines', 'audubon:audubon_beluga_polys', 'audubon:audubon_blgu_polys', 'audubon:audubon_bowhead_fall', 'audubon:audubon_bowhead_huntareas', 'audubon:audubon_bowhead_lines', 'audubon:audubon_bowhead_polys', 'audubon:audubon_bowhead_quiet', 'audubon:audubon_bowhead_spring', 'audubon:audubon_bowhead_summer', 'audubon:audubon_bowhead_winter', 'audubon:audubon_capelin_lines', 'audubon:audubon_capelin_polys', 'audubon:audubon_chumsalmon_polys', 'audubon:audubon_coei_polys', 'audubon:audubon_euphausiids_polys', 'audubon:audubon_falsecalunuscopepods_polys', 'audubon:audubon_gray_polys', 'audubon:audubon_ibas', 'audubon:audubon_kiei_polys', 'audubon:audubon_kimu_polys', 'audubon:audubon_ltdu_polys', 'audubon:audubon_murre_polys', 'audubon:audubon_nofu_polys', 'audubon:audubon_opiliotannercrab_polys', 'audubon:audubon_pacificherring_lines', 'audubon:audubon_pacificherring_polys', 'audubon:audubon_pinksalmon_polys', 'audubon:audubon_polarbear_polys', 'audubon:audubon_ribbonseal_polys', 'audubon:audubon_ringedseal_polys', 'audubon:audubon_rogu_polys', 'audubon:audubon_rtlo_polys', 'audubon:audubon_saffroncod_polys', 'audubon:audubon_shoals', 'audubon:audubon_spei_polys', 'audubon:audubon_spottedseal_polys', 'audubon:audubon_stei_polys', 'audubon:audubon_stsh_polys', 'audubon:audubon_walrus_lines', 'audubon:audubon_walrus_polys', 'audubon:audubon_yblo_polys']\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### We already know that the 'audubon:audubon_ibas' layer is Import Bird Areas.  Request 'geojson' response from the layer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import geojson\n",
      "geojson_response = wfs.getfeature(typename=['audubon:audubon_ibas'], maxfeatures=1, outputFormat=\"application/json\", srsname=\"urn:x-ogc:def:crs:EPSG:4326\").read()\n",
      "feature = geojson.loads(geojson_response)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### Convert to Shapely geometry objects"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from shapely.geometry import shape\n",
      "shapes = [shape(s.get(\"geometry\")) for s in feature.get(\"features\")]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### Map the geometry objects"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import folium\n",
      "map_center = shapes[0].centroid\n",
      "mapper = folium.Map(location=[map_center.x, map_center.y], zoom_start=6)\n",
      "for s in shapes:\n",
      "    if hasattr(s.boundary, 'coords'):\n",
      "        mapper.line(s.boundary.coords, line_color='#FF0000', line_weight=5)\n",
      "    else:\n",
      "        for p in s:\n",
      "            mapper.line(p.boundary.coords, line_color='#FF0000', line_weight=5)\n",
      "mapper._build_map()\n",
      "\n",
      "from IPython.core.display import HTML\n",
      "HTML('<iframe srcdoc=\"{srcdoc}\" style=\"width: 100%; height: 535px; border: none\"></iframe>'.format(srcdoc=mapper.HTML.replace('\"', '&quot;')))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<iframe srcdoc=\"<!DOCTYPE html>\n",
        "<head>\n",
        "   <meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; />\n",
        "   <link rel=&quot;stylesheet&quot; href=&quot;http://cdn.leafletjs.com/leaflet-0.7.2/leaflet.css&quot; />\n",
        "   <script src=&quot;http://cdn.leafletjs.com/leaflet-0.7.2/leaflet.js&quot;></script>\n",
        "\n",
        "   \n",
        "   \n",
        "   \n",
        "   \n",
        "\n",
        "\n",
        "   <style>\n",
        "\n",
        "      #map {\n",
        "        position:absolute;\n",
        "        top:0;\n",
        "        bottom:0;\n",
        "        right:0;\n",
        "        left:0;\n",
        "      }\n",
        "\n",
        "   </style>\n",
        "</head>\n",
        "\n",
        "<body>\n",
        "\n",
        "   <div class=&quot;folium-map&quot; id=&quot;folium_c25e192b47414ac59170ca83b6cede38&quot; style=&quot;width: 960px; height: 500px&quot;></div>\n",
        "\n",
        "   <script>\n",
        "\n",
        "      \n",
        "\n",
        "      var map = L.map('folium_c25e192b47414ac59170ca83b6cede38').setView([67.1296184796, -163.609704909], 6);\n",
        "\n",
        "      L.tileLayer('http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', {\n",
        "          maxZoom: 18,\n",
        "          attribution: 'Map data (c) <a href=&quot;http://openstreetmap.org&quot;>OpenStreetMap</a> contributors'\n",
        "      }).addTo(map);\n",
        "\n",
        "      \n",
        "\n",
        "      \n",
        "      var latLngs = [ [67.0608961817, -163.320031024],  [67.0602428191, -163.3208159],  [67.0565231832, -163.324883992],  [67.0547395712, -163.326008631],  [67.0487261279, -163.340202761],  [67.0433757176, -163.358909849],  [67.041722233, -163.38830634],  [67.0424294049, -163.434691824],  [67.0481899891, -163.50201161],  [67.0526320227, -163.534928793],  [67.0585309828, -163.575105898],  [67.0659591118, -163.61898997],  [67.0716147157, -163.6592729],  [67.0772826826, -163.700158255],  [67.0826625496, -163.734646083],  [67.0908310694, -163.775449893],  [67.1015130403, -163.805530606],  [67.1120761998, -163.822075412],  [67.1223623339, -163.837528654],  [67.1346464594, -163.845930161],  [67.1481395268, -163.850452276],  [67.1631732472, -163.853365277],  [67.1757385733, -163.852229223],  [67.1859677875, -163.8499659],  [67.1950339775, -163.847431213],  [67.2058698893, -163.843216076],  [67.2133770061, -163.8417068],  [67.2211636619, -163.835963255],  [67.2251489111, -163.827127188],  [67.2283335991, -163.815540647],  [67.2307384888, -163.801795796],  [67.2305262319, -163.780470764],  [67.2244971305, -163.741195316],  [67.2165270619, -163.694177287],  [67.207654712, -163.642699754],  [67.1978861056, -163.592108908],  [67.1867014798, -163.55145859],  [67.173882224, -163.520811802],  [67.1589879568, -163.469471641],  [67.1440834764, -163.423522344],  [67.1354935258, -163.405939586],  [67.1259140454, -163.386888253],  [67.1167430575, -163.371870825],  [67.1037597841, -163.353864424],  [67.0948216907, -163.34412299],  [67.089522283, -163.338617964],  [67.0851297911, -163.332842926],  [67.0782281221, -163.322504794],  [67.0734340433, -163.318037531],  [67.0672260576, -163.312814659],  [67.0637749993, -163.312671675],  [67.0608961817, -163.320031024], ];\n",
        "var line_1 = L.polyline(latLngs,{\n",
        "color: '#FF0000',\n",
        "weight: 5,\n",
        "\n",
        "});\n",
        "      map.addLayer(line_1);\n",
        "      \n",
        "\n",
        "      \n",
        "\n",
        "      \n",
        "\n",
        "   </script>\n",
        "\n",
        "</body>\" style=\"width: 100%; height: 535px; border: none\"></iframe>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "<IPython.core.display.HTML at 0x4701950>"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Can we discover other datasets in this polygon area?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### Setup BCSW Filters to find models in the area of the Important Bird Polygon"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from owslib import fes \n",
      "\n",
      "# Polygon filters\n",
      "polygon_filters = []\n",
      "for s in shapes:\n",
      "    f = fes.BBox(bbox=list(reversed(s.bounds)))\n",
      "    polygon_filters.append(f)\n",
      "# If we have more than one polygon filter, OR them together\n",
      "if len(polygon_filters) > 1:\n",
      "    polygon_filters = fes.Or(polygon_filters)\n",
      "elif len(polygon_filters) == 1:\n",
      "    polygon_filters = polygon_filters[0]\n",
      "    \n",
      "# Name filters\n",
      "name_filters = []\n",
      "model_strings = ['roms', 'selfe', 'adcirc', 'ncom', 'hycom', 'fvcom', 'wrf']\n",
      "for model in model_strings:\n",
      "    title_filter   = fes.PropertyIsLike(propertyname='apiso:Title',   literal='*%s*' % model, wildCard='*')\n",
      "    name_filters.append(title_filter)\n",
      "    subject_filter = fes.PropertyIsLike(propertyname='apiso:Subject', literal='*%s*' % model, wildCard='*')\n",
      "    name_filters.append(subject_filter)\n",
      "# Or all of the name filters together\n",
      "name_filters = fes.Or(name_filters)\n",
      "\n",
      "# Final filters\n",
      "filters = fes.And([polygon_filters, name_filters])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### The actual CSW filters look like this"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from owslib.etree import etree\n",
      "print etree.tostring(filters.toXML(), pretty_print=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<ogc:And xmlns:ogc=\"http://www.opengis.net/ogc\">\n",
        "  <ogc:BBOX>\n",
        "    <ogc:PropertyName>ows:BoundingBox</ogc:PropertyName>\n",
        "    <gml311:Envelope xmlns:gml311=\"http://www.opengis.net/gml\">\n",
        "      <gml311:lowerCorner>-163.312671675 67.2307384888</gml311:lowerCorner>\n",
        "      <gml311:upperCorner>-163.853365277 67.041722233</gml311:upperCorner>\n",
        "    </gml311:Envelope>\n",
        "  </ogc:BBOX>\n",
        "  <ogc:Or>\n",
        "    <ogc:PropertyIsLike wildCard=\"*\" singleChar=\"_\" escapeChar=\"\\\">\n",
        "      <ogc:PropertyName>apiso:Title</ogc:PropertyName>\n",
        "      <ogc:Literal>*roms*</ogc:Literal>\n",
        "    </ogc:PropertyIsLike>\n",
        "    <ogc:PropertyIsLike wildCard=\"*\" singleChar=\"_\" escapeChar=\"\\\">\n",
        "      <ogc:PropertyName>apiso:Subject</ogc:PropertyName>\n",
        "      <ogc:Literal>*roms*</ogc:Literal>\n",
        "    </ogc:PropertyIsLike>\n",
        "    <ogc:PropertyIsLike wildCard=\"*\" singleChar=\"_\" escapeChar=\"\\\">\n",
        "      <ogc:PropertyName>apiso:Title</ogc:PropertyName>\n",
        "      <ogc:Literal>*selfe*</ogc:Literal>\n",
        "    </ogc:PropertyIsLike>\n",
        "    <ogc:PropertyIsLike wildCard=\"*\" singleChar=\"_\" escapeChar=\"\\\">\n",
        "      <ogc:PropertyName>apiso:Subject</ogc:PropertyName>\n",
        "      <ogc:Literal>*selfe*</ogc:Literal>\n",
        "    </ogc:PropertyIsLike>\n",
        "    <ogc:PropertyIsLike wildCard=\"*\" singleChar=\"_\" escapeChar=\"\\\">\n",
        "      <ogc:PropertyName>apiso:Title</ogc:PropertyName>\n",
        "      <ogc:Literal>*adcirc*</ogc:Literal>\n",
        "    </ogc:PropertyIsLike>\n",
        "    <ogc:PropertyIsLike wildCard=\"*\" singleChar=\"_\" escapeChar=\"\\\">\n",
        "      <ogc:PropertyName>apiso:Subject</ogc:PropertyName>\n",
        "      <ogc:Literal>*adcirc*</ogc:Literal>\n",
        "    </ogc:PropertyIsLike>\n",
        "    <ogc:PropertyIsLike wildCard=\"*\" singleChar=\"_\" escapeChar=\"\\\">\n",
        "      <ogc:PropertyName>apiso:Title</ogc:PropertyName>\n",
        "      <ogc:Literal>*ncom*</ogc:Literal>\n",
        "    </ogc:PropertyIsLike>\n",
        "    <ogc:PropertyIsLike wildCard=\"*\" singleChar=\"_\" escapeChar=\"\\\">\n",
        "      <ogc:PropertyName>apiso:Subject</ogc:PropertyName>\n",
        "      <ogc:Literal>*ncom*</ogc:Literal>\n",
        "    </ogc:PropertyIsLike>\n",
        "    <ogc:PropertyIsLike wildCard=\"*\" singleChar=\"_\" escapeChar=\"\\\">\n",
        "      <ogc:PropertyName>apiso:Title</ogc:PropertyName>\n",
        "      <ogc:Literal>*hycom*</ogc:Literal>\n",
        "    </ogc:PropertyIsLike>\n",
        "    <ogc:PropertyIsLike wildCard=\"*\" singleChar=\"_\" escapeChar=\"\\\">\n",
        "      <ogc:PropertyName>apiso:Subject</ogc:PropertyName>\n",
        "      <ogc:Literal>*hycom*</ogc:Literal>\n",
        "    </ogc:PropertyIsLike>\n",
        "    <ogc:PropertyIsLike wildCard=\"*\" singleChar=\"_\" escapeChar=\"\\\">\n",
        "      <ogc:PropertyName>apiso:Title</ogc:PropertyName>\n",
        "      <ogc:Literal>*fvcom*</ogc:Literal>\n",
        "    </ogc:PropertyIsLike>\n",
        "    <ogc:PropertyIsLike wildCard=\"*\" singleChar=\"_\" escapeChar=\"\\\">\n",
        "      <ogc:PropertyName>apiso:Subject</ogc:PropertyName>\n",
        "      <ogc:Literal>*fvcom*</ogc:Literal>\n",
        "    </ogc:PropertyIsLike>\n",
        "    <ogc:PropertyIsLike wildCard=\"*\" singleChar=\"_\" escapeChar=\"\\\">\n",
        "      <ogc:PropertyName>apiso:Title</ogc:PropertyName>\n",
        "      <ogc:Literal>*wrf*</ogc:Literal>\n",
        "    </ogc:PropertyIsLike>\n",
        "    <ogc:PropertyIsLike wildCard=\"*\" singleChar=\"_\" escapeChar=\"\\\">\n",
        "      <ogc:PropertyName>apiso:Subject</ogc:PropertyName>\n",
        "      <ogc:Literal>*wrf*</ogc:Literal>\n",
        "    </ogc:PropertyIsLike>\n",
        "  </ogc:Or>\n",
        "</ogc:And>\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### Find all models contain in all CSW endpoints"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from owslib.csw import CatalogueServiceWeb\n",
      "endpoints = ['http://www.nodc.noaa.gov/geoportal/csw',\n",
      "             'http://www.ngdc.noaa.gov/geoportal/csw',\n",
      "             'http://catalog.data.gov/csw-all',\n",
      "             #'http://cwic.csiss.gmu.edu/cwicv1/discovery',\n",
      "             'http://geoport.whoi.edu/geoportal/csw',\n",
      "             'https://edg.epa.gov/metadata/csw',\n",
      "             'http://cmgds.marine.usgs.gov/geonetwork/srv/en/csw',\n",
      "             'http://cida.usgs.gov/gdp/geonetwork/srv/en/csw',\n",
      "             'http://geodiscover.cgdi.ca/wes/serviceManagerCSW/csw', \n",
      "             'http://geoport.whoi.edu/gi-cat/services/cswiso']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### Filter out CSW servers that do not support a BBOX query"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bbox_endpoints = []\n",
      "for url in endpoints:\n",
      "    queryables = []\n",
      "    try:\n",
      "        csw = CatalogueServiceWeb(url, timeout=20)\n",
      "    except BaseException:\n",
      "        print \"Failure - %s - Timed out\" % url\n",
      "    if \"BBOX\" in csw.filters.spatial_operators:\n",
      "        print \"Success - %s - BBOX Query supported\" % url\n",
      "        bbox_endpoints.append(url)    \n",
      "    else:\n",
      "        print \"Failure - %s - BBOX Query NOT supported\" % url"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Success - http://www.nodc.noaa.gov/geoportal/csw - BBOX Query supported\n",
        "Success - http://www.ngdc.noaa.gov/geoportal/csw - BBOX Query supported"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Success - http://catalog.data.gov/csw-all - BBOX Query supported"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Success - http://geoport.whoi.edu/geoportal/csw - BBOX Query supported"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Success - https://edg.epa.gov/metadata/csw - BBOX Query supported"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Success - http://cmgds.marine.usgs.gov/geonetwork/srv/en/csw - BBOX Query supported"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Success - http://cida.usgs.gov/gdp/geonetwork/srv/en/csw - BBOX Query supported"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Success - http://geodiscover.cgdi.ca/wes/serviceManagerCSW/csw - BBOX Query supported"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Success - http://geoport.whoi.edu/gi-cat/services/cswiso - BBOX Query supported"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for url in bbox_endpoints:\n",
      "    try:\n",
      "        csw = CatalogueServiceWeb(url, timeout=20)\n",
      "        csw.getrecords2(constraints=[filters], maxrecords=1000, esn='full')\n",
      "        for record, item in csw.records.items():\n",
      "            print \"*\", item.title\n",
      "    except BaseException as e:\n",
      "        print \"* FAILED\", url, e.msg "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "* Clean Catalog for NCOM forecast models/NCOM Region 1 Aggregation/NCOM Region 1 Best Time Series\n",
        "* Clean Catalog for NCOM forecast models/NCOM Region 2 Aggregation/NCOM Region 2 Best Time Series\n",
        "* Clean Catalog for NCOM forecast models/NCOM Region 6 Aggregation/NCOM Region 6 Best Time Series\n",
        "* U.S. Navy Coastal Ocean Model (NCOM): Global\n",
        "* GFDL CM2.0, 20C3M (run 3) climate of the 20th Century experiment (20C3M) output for IPCC AR4 and US CCSP\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual Experimental Forecasts CM2.1U_CDAef_v1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* model output prepared for GFDL Seasonal-Interannual experimental forecasts - CM2.1U_CDAef_V1.0\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* GFDL CM2.0, 20C3M (run 1) climate of the 20th Century experiment (20C3M) output for IPCC AR4 and US CCSP\n",
        "* GFDL CM2.0, 20C3M (run 1) climate of the 20th Century experiment (20C3M) output for IPCC AR4 and US CCSP\n",
        "* GFDL CM2.0, 20C3M (run 2) climate of the 20th Century experiment (20C3M) output for IPCC AR4 and US CCSP\n",
        "* GFDL CM2.0, 20C3M (run 2) climate of the 20th Century experiment (20C3M) output for IPCC AR4 and US CCSP\n",
        "* GFDL CM2.0, 20C3M (run 3) climate of the 20th Century experiment (20C3M) output for IPCC AR4 and US CCSP\n",
        "* CLIVAR model output prepared for GFDL Seasonal-Interannual Experimental Forecasts Coupled Data Assimilation Experiment\n",
        "* HYCOM Region 6 Aggregation/Best Time Series\n",
        "* HYCOM Surface Aggregation/Best Time Series\n",
        "* NCOM Region 1 Aggregation/Best Time Series\n",
        "* NCOM Region 2 Aggregation/Best Time Series\n",
        "* NCOM Region 6 Aggregation/Best Time Series\n",
        "* NCOM SFC 8 Aggregation/Best Time Series\n",
        "* NCOM SFC8 Hindcast Aggregation/Best Time Series\n",
        "*"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Multibeam collection for HLY0503: Multibeam data collected aboard Healy from 2005-08-04 to 2005-09-29, departing from Dutch Harbor, AK and returning to Tromso, Norway\n",
        "* Nighttime Lights Annual Composites V4\n",
        "* Multibeam collection for HLY0103: Multibeam data collected aboard Healy from 2001-10-27 to 2001-11-28, departing from Tromso, Norway and returning to Tromso, Norway\n",
        "* Multibeam collection for HLY05TE: Multibeam data collected aboard Healy from 2005-09-29 to 2005-11-03, departing from Tromso, Norway and returning to Dublin, Ireland\n",
        "* HYCOM GLBa0.08\n",
        "* HYCOM Region 6 Aggregation/Best Time Series\n",
        "* HYCOM Surface Aggregation/Best Time Series\n",
        "* NCOM Region 1 Aggregation/Best Time Series\n",
        "* NCOM Region 2 Aggregation/Best Time Series\n",
        "* NCOM Region 6 Aggregation/Best Time Series\n",
        "* NCOM SFC 8 Aggregation/Best Time Series\n",
        "* NCOM SFC8 Hindcast Aggregation/Best Time Series\n",
        "* HYCOM GLBa0.08\n",
        "* DAP Server For RPSASA Environmental Data Server/Navy HYCOM Aggregation\n",
        "*"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " HYCOM GLBa0.08\n",
        "*"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " R2 & NE: County Level 2006-2010 ACS Income Summary\n",
        "* R2 & NE: State Level 2006-2010 ACS Income Summary\n",
        "* R2 & NE: Tract Level 2006-2010 ACS Income Summary\n",
        "* FAILED"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " http://geodiscover.cgdi.ca/wes/serviceManagerCSW/csw ORA-00907: missing right parenthesis\n"
       ]
      },
      {
       "ename": "AttributeError",
       "evalue": "CatalogueServiceWeb instance has no attribute 'records'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-40-a3834d997654>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m\"* FAILED\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcsw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m\"*\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mAttributeError\u001b[0m: CatalogueServiceWeb instance has no attribute 'records'"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### Get bounding polygons from each dataset "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from paegan.cdm.dataset import CommonDataset\n",
      "\n",
      "dataset_polygons = {}\n",
      "for dap in dap_urls:\n",
      "    cd = CommonDataset.open(dap)\n",
      "    var = cd.get_varname_from_stdname(standard_name=\"air_temperature\")\n",
      "    # var = cd.get_varname_from_stdname(standard_name=\"sea_water_temperature\")\n",
      "    if var:\n",
      "        dataset_polygons[dap] = cd.getboundingpolygon(var=var)\n",
      "    else:\n",
      "        print \"No standard_name 'air_temperature' in\", dap\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'dap_urls' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-43-3657964e4edb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdataset_polygons\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mdap\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdap_urls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mcd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCommonDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_varname_from_stdname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstandard_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"air_temperature\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'dap_urls' is not defined"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### Overlay dataset polygons on top of Important Bird Area polygons"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "for p in dataset_polygons:\n",
      "    color = \"%06x\" % random.randint(0,0xFFFFFF)\n",
      "    map.line(p.boundary.coords, line_color=color, line_weight=5)\n",
      "    \n",
      "map._build_map()\n",
      "\n",
      "from IPython.core.display import HTML\n",
      "HTML('<iframe srcdoc=\"{srcdoc}\" style=\"width: 100%; height: 535px; border: none\"></iframe>'.format(srcdoc=map.HTML.replace('\"', '&quot;')))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'dataset_polygons' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-41-e94902fe5716>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset_polygons\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%06x\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0xFFFFFF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboundary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline_color\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'dataset_polygons' is not defined"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}