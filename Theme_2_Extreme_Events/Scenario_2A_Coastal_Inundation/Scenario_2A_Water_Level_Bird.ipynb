{
 "metadata": {
  "name": "",
  "signature": "sha256:32162b0bb63b59ec9124d24138987e7f53c7eef850c21596316f8c8684871c24"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "># IOOS System Test: [Extreme Events Theme:](https://github.com/ioos/system-test/wiki/Development-of-Test-Themes#theme-2-extreme-events) Inundation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Can we estimate the return period of a water level by comparing modeled and/or observed water levels with NOAA exceedance probability plots?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "import required libraries"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "from pylab import *\n",
      "import sys\n",
      "import csv\n",
      "import json\n",
      "from scipy.stats import genextreme\n",
      "import numpy as np\n",
      "\n",
      "from owslib.csw import CatalogueServiceWeb\n",
      "from owslib import fes\n",
      "import random\n",
      "import netCDF4\n",
      "import pandas as pd\n",
      "import datetime as dt\n",
      "from pyoos.collectors.coops.coops_sos import CoopsSos\n",
      "import cStringIO\n",
      "#import iris\n",
      "import urllib2\n",
      "import parser\n",
      "from lxml import etree       #TODO suggest using bs4 instead for ease of access to XML objects\n",
      "\n",
      "#generated for csw interface\n",
      "import requests              #required for the processing of requests\n",
      "from utilities import * "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "some functions from [Rich Signell Notebook](http://nbviewer.ipython.org/github/rsignell-usgs/notebook/blob/fef9438303b49a923024892db1ef3115e34d8271/CSW/IOOS_inundation.ipynb)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Speficy Temporal and Spatial conditions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import HTML\n",
      "import folium #required for leaflet mapping\n",
      "\n",
      "#bounding box of interest,[bottom right[lat,lon], top left[lat,lon]]\n",
      "bounding_box_type = \"box\" \n",
      "bounding_box = [[-73.94,40.67],[-69.94,42]]\n",
      "\n",
      "#temporal range\n",
      "start_date = dt.datetime(1991,5,1).strftime('%Y-%m-%d %H:00')\n",
      "end_date = dt.datetime(2014,5,7).strftime('%Y-%m-%d %H:00')\n",
      "time_date_range = [start_date,end_date]  #start_date_end_date\n",
      "\n",
      "print start_date,'to',end_date"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1991-05-01 00:00 to 2014-05-07 00:00\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "endpoint = 'http://www.ngdc.noaa.gov/geoportal/csw' # NGDC Geoportal\n",
      "csw = CatalogueServiceWeb(endpoint,timeout=60)\n",
      "\n",
      "for oper in csw.operations:\n",
      "    if oper.name == 'GetRecords':\n",
      "        #print '\\nISO Queryables:\\n',oper.constraints['SupportedISOQueryables']['values']\n",
      "        pass\n",
      "        \n",
      "#put the names in a dict for ease of access \n",
      "data_dict = {}\n",
      "data_dict[\"water\"] = {\"names\":['water_surface_height_above_reference_datum',\n",
      "    'sea_surface_height_above_geoid','sea_surface_elevation',\n",
      "    'sea_surface_height_above_reference_ellipsoid','sea_surface_height_above_sea_level',\n",
      "    'sea_surface_height','water level'], \"sos_name\":['water_surface_height_above_reference_datum']}      "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dateRange(start_date='1900-01-01',stop_date='2100-01-01',constraint='overlaps'):\n",
      "    if constraint == 'overlaps':\n",
      "        start = fes.PropertyIsLessThanOrEqualTo(propertyname='apiso:TempExtent_begin', literal=stop_date)\n",
      "        stop = fes.PropertyIsGreaterThanOrEqualTo(propertyname='apiso:TempExtent_end', literal=start_date)\n",
      "    elif constraint == 'within':\n",
      "        start = fes.PropertyIsGreaterThanOrEqualTo(propertyname='apiso:TempExtent_begin', literal=start_date)\n",
      "        stop = fes.PropertyIsLessThanOrEqualTo(propertyname='apiso:TempExtent_end', literal=stop_date)\n",
      "    return start,stop"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# convert User Input into FES filters\n",
      "start,stop = dateRange(start_date,end_date)\n",
      "box = []\n",
      "box.append(bounding_box[0][0])\n",
      "box.append(bounding_box[0][1])\n",
      "box.append(bounding_box[1][0])\n",
      "box.append(bounding_box[1][1])\n",
      "bbox = fes.BBox(box)\n",
      "\n",
      "or_filt = fes.Or([fes.PropertyIsLike(propertyname='apiso:AnyText',literal=('*%s*' % val),\n",
      "                    escapeChar='\\\\',wildCard='*',singleChar='?') for val in name_list])\n",
      "val = 'Averages'\n",
      "not_filt = fes.Not([fes.PropertyIsLike(propertyname='apiso:AnyText',literal=('*%s*' % val),\n",
      "                        escapeChar='\\\\',wildCard='*',singleChar='?')])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filter_list = [fes.And([ bbox, start, stop, or_filt, not_filt]) ]\n",
      "# connect to CSW, explore it's properties\n",
      "# try request using multiple filters \"and\" syntax: [[filter1,filter2]]\n",
      "csw.getrecords2(constraints=filter_list,maxrecords=1000,esn='full')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def service_urls(records,service_string='urn:x-esri:specification:ServiceType:odp:url'):\n",
      "    \"\"\"\n",
      "    extract service_urls of a specific type (DAP, SOS) from records\n",
      "    \"\"\"\n",
      "    urls=[]\n",
      "    for key,rec in records.iteritems():\n",
      "        #create a generator object, and iterate through it until the match is found\n",
      "        #if not found, gets the default value (here \"none\")\n",
      "        url = next((d['url'] for d in rec.references if d['scheme'] == service_string), None)\n",
      "        if url is not None:\n",
      "            urls.append(url)\n",
      "    return urls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print records that are available\n",
      "print \"number of datasets available: \",len(csw.records.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "number of datasets available:  216\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Print all the records (should you want too)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print \"\\n\".join(csw.records)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Dap URLS"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dap_urls = service_urls(csw.records,service_string='urn:x-esri:specification:ServiceType:odp:url')\n",
      "#remove duplicates and organize\n",
      "dap_urls = sorted(set(dap_urls))\n",
      "print \"Total DAP:\",len(dap_urls)\n",
      "#print the first 5...\n",
      "print \"\\n\".join(dap_urls[0:5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total DAP: 23\n",
        "http://colossus.dl.stevens-tech.edu/thredds/dodsC/latest/Complete_gcmplt.nc\n",
        "http://comt.sura.org/thredds/dodsC/data/comt_1_archive/inundation_tropical/VIMS_SELFE/Hurricane_Ike_2D_final_run_wave_only\n",
        "http://comt.sura.org/thredds/dodsC/data/comt_1_archive/inundation_tropical/VIMS_SELFE/Hurricane_Ike_2D_final_run_with_waves\n",
        "http://comt.sura.org/thredds/dodsC/data/comt_1_archive/inundation_tropical/VIMS_SELFE/Hurricane_Ike_2D_final_run_without_waves\n",
        "http://comt.sura.org/thredds/dodsC/data/comt_1_archive/inundation_tropical/VIMS_SELFE/Hurricane_Ike_3D_final_run_with_waves\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "SOS URLs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sos_urls = service_urls(csw.records,service_string='urn:x-esri:specification:ServiceType:sos:url')\n",
      "#remove duplicates and organize\n",
      "sos_urls = sorted(set(sos_urls))\n",
      "print \"Total SOS:\",len(sos_urls)\n",
      "print \"\\n\".join(sos_urls)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total SOS: 1\n",
        "http://opendap.co-ops.nos.noaa.gov/ioos-dif-sos/SOS?service=SOS&request=GetCapabilities\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### SOS Requirements"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#use the get caps to get station start and get time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start_time = dt.datetime.strptime(start_date,'%Y-%m-%d %H:%M')\n",
      "end_time = dt.datetime.strptime(end_date,'%Y-%m-%d %H:%M')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iso_start = start_time.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
      "iso_end = end_time.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
      "\n",
      "collector = CoopsSos()\n",
      "collector.set_datum('NAVD')\n",
      "collector.server.identification.title\n",
      "collector.start_time = start_time\n",
      "collector.end_time = end_time\n",
      "collector.variables = [data_dict[\"water\"][\"sos_name\"]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Date: \",iso_start,\" to \", iso_end\n",
      "box_str=','.join(str(e) for e in box)\n",
      "print \"Lat/Lon Box: \",box_str\n",
      "#grab the sos url and use it for the service\n",
      "url=(sos_urls[0].split(\"?\")[0]+'?'\n",
      "     'service=SOS&request=GetObservation&version=1.0.0&'\n",
      "     'observedProperty=%s&offering=urn:ioos:network:NOAA.NOS.CO-OPS:WaterLevelActive&'\n",
      "     'featureOfInterest=BBOX:%s&responseFormat=text/tab-separated-values&eventTime=%s') % (sos_name,box_str,iso_end)\n",
      "\n",
      "r = requests.get(url)\n",
      "data = r.text\n",
      "#get the headers for the cols\n",
      "data = data.split(\"\\n\")\n",
      "headers =  data[0]\n",
      "station_list_dict = dict()\n",
      "#parse the headers so i can create a dict\n",
      "c = 0\n",
      "for h in headers.split(\"\\t\"):\n",
      "    field = h.split(\":\")[0].split(\" \")[0]\n",
      "    station_list_dict[field] = {\"id\":c}\n",
      "    c+=1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Date:  1991-05-01T00:00:00Z  to  2014-05-07T00:00:00Z\n",
        "Lat/Lon Box:  -73.94,40.67,-69.94,42\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_coops_longName(sta):\n",
      "    \"\"\"\n",
      "    get longName for specific station from COOPS SOS using DescribeSensor request\n",
      "    \"\"\"\n",
      "    url=(sos_urls[0].split(\"?\")[0]+'?service=SOS&'\n",
      "        'request=DescribeSensor&version=1.0.0&outputFormat=text/xml;subtype=\"sensorML/1.0.1\"&'\n",
      "        'procedure=%s') % sta\n",
      "    tree = etree.parse(urllib2.urlopen(url))\n",
      "    root = tree.getroot()\n",
      "    longName=root.xpath(\"//sml:identifier[@name='longName']/sml:Term/sml:value/text()\", namespaces={'sml':\"http://www.opengis.net/sensorML/1.0.1\"})\n",
      "    return longName"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#finds the max value given a json object\n",
      "def findMaxVal(data):\n",
      "    dates_array = []\n",
      "    vals_array = []\n",
      "    for x in data:\n",
      "        dates_array.append(str(x[\"t\"]))\n",
      "        vals_array.append(x[\"v\"])\n",
      "    \n",
      "    p = np.array(vals_array,dtype=np.float)\n",
      "    x = np.arange(len(p))\n",
      "    max_val = np.amax(p)\n",
      "    max_idx = np.argmax(p)\n",
      "    return (max_val,len(p),dates_array[max_idx])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def coops2data(collector,station_id,sos_name):\n",
      "    collector.features = [station_id]\n",
      "    collector.variables = [sos_name]\n",
      "    station_data = dict()\n",
      "    #loop through the years and get the data needed\n",
      "    for year_station in range(int(collector.start_time.year),collector.end_time.year+1):      \n",
      "        link = \"http://tidesandcurrents.noaa.gov/api/datagetter?product=\"+sos_name+\"&application=NOS.COOPS.TAC.WL&\"\n",
      "        date1 = \"begin_date=\"+str(year_station)+\"0101\"\n",
      "        date2 = \"&end_date=\"+str(year_station)+\"1231\"\n",
      "        datum = \"&datum=MLLW\"\n",
      "        station_request = \"&station=\"+station_id+\"&time_zone=GMT&units=english&format=json\"\n",
      "        http_request = link+date1+date2+datum+station_request\n",
      "        d_r = requests.get(http_request,timeout=10)\n",
      "        if \"Great Lake station\" in d_r.text:\n",
      "            pass\n",
      "        else:\n",
      "            key_list =  d_r.json().keys()\n",
      "            if \"data\" in key_list:\n",
      "                data = d_r.json()['data']\n",
      "                max_value,num_samples,date_string = findMaxVal(data)\n",
      "                station_data[str(year_station)] =  {\"max\":max_value,\"num_samples\":num_samples,\"date_string\":date_string}\n",
      "                #print \"\\tyear:\",year_station,\" MaxValue:\",max_value\n",
      "    return station_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create dict of stations\n",
      "station_list = []\n",
      "for i in range(1,len(data)):\n",
      "    station_info = data[i].split(\"\\t\")\n",
      "    station = dict()\n",
      "    for field in station_list_dict.keys():        \n",
      "        col = station_list_dict[field][\"id\"]\n",
      "        if col < len(station_info):\n",
      "            station[field] = station_info[col]     \n",
      "    station_list.append(station)        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Embeds the HTML source of the map directly into the IPython notebook.\n",
      "def inline_map(map):   \n",
      "    map._build_map()\n",
      "    return HTML('<iframe srcdoc=\"{srcdoc}\" style=\"width: 100%; height: 500px; border: none\"></iframe>'.format(srcdoc=map.HTML.replace('\"', '&quot;')))\n",
      "\n",
      "map = folium.Map(location=[40, -99], zoom_start=4)\n",
      "\n",
      "station_yearly_max = []\n",
      "for s in station_list:\n",
      "    #get the long name\n",
      "    s[\"long_name\"] =get_coops_longName(s['station_id'])\n",
      "    #get the data\n",
      "    station_num = str(s['station_id']).split(':')[-1]\n",
      "    s[\"station_num\"] = station_num\n",
      "    #this is different than sos name, hourly height is hourly water level\n",
      "    data = coops2data(collector,station_num,\"hourly_height\")    \n",
      "    s[\"data\"] = data\n",
      "    if \"latitude\" in s:\n",
      "        popup_string = '<b>Station:</b><br>'+str(s['station_id']) + \"<br><b>Long Name:</b><br>\"+str(s[\"long_name\"])\n",
      "        map.simple_marker([s[\"latitude\"],s[\"longitude\"]],popup=popup_string)\n",
      "   \n",
      "    #break after the first one    \n",
      "    break\n",
      "# Create the map and add the bounding box line\n",
      "map.line(get_coordinates(bounding_box,bounding_box_type), line_color='#FF0000', line_weight=5)\n",
      "\n",
      "inline_map(map)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<iframe srcdoc=\"<!DOCTYPE html>\n",
        "<head>\n",
        "   <meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; />\n",
        "   <link rel=&quot;stylesheet&quot; href=&quot;http://cdn.leafletjs.com/leaflet-0.7.2/leaflet.css&quot; />\n",
        "   <script src=&quot;http://cdn.leafletjs.com/leaflet-0.7.2/leaflet.js&quot;></script>\n",
        "\n",
        "   \n",
        "   \n",
        "   \n",
        "   \n",
        "\n",
        "\n",
        "   <style>\n",
        "\n",
        "      #map {\n",
        "        position:absolute;\n",
        "        top:0;\n",
        "        bottom:0;\n",
        "        right:0;\n",
        "        left:0;\n",
        "      }\n",
        "\n",
        "   </style>\n",
        "</head>\n",
        "\n",
        "<body>\n",
        "\n",
        "   <div class=&quot;folium-map&quot; id=&quot;folium_20692683df1d4c888e9d96adee0883ea&quot; style=&quot;width: 960px; height: 500px&quot;></div>\n",
        "\n",
        "   <script>\n",
        "\n",
        "      \n",
        "\n",
        "      var map = L.map('folium_20692683df1d4c888e9d96adee0883ea').setView([40, -99], 4);\n",
        "\n",
        "      L.tileLayer('http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', {\n",
        "          maxZoom: 18,\n",
        "          attribution: 'Map data (c) <a href=&quot;http://openstreetmap.org&quot;>OpenStreetMap</a> contributors'\n",
        "      }).addTo(map);\n",
        "\n",
        "      \n",
        "      var marker_1 = L.marker([41.7043, -71.1641]);\n",
        "      marker_1.bindPopup(&quot;<b>Station:</b><br>urn:ioos:station:NOAA.NOS.CO-OPS:8447386<br><b>Long Name:</b><br>['Fall River, MA']&quot;);\n",
        "      map.addLayer(marker_1)\n",
        "      \n",
        "\n",
        "      \n",
        "      var latLngs = [ [40.67, -73.94],  [40.67, -69.94],  [42, -69.94],  [42, -73.94],  [40.67, -73.94], ];\n",
        "var line_1 = L.polyline(latLngs,{\n",
        "color: '#FF0000',\n",
        "weight: 5,\n",
        "\n",
        "});\n",
        "      map.addLayer(line_1);\n",
        "      \n",
        "\n",
        "      \n",
        "\n",
        "      \n",
        "\n",
        "   </script>\n",
        "\n",
        "</body>\" style=\"width: 100%; height: 500px; border: none\"></iframe>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "<IPython.core.display.HTML at 0x594e550>"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import prettyplotlib as ppl\n",
      "import matplotlib.pyplot as plt\n",
      "# Set the random seed for consistency\n",
      "np.random.seed(12)\n",
      "\n",
      "fig, ax = plt.subplots(1)\n",
      "\n",
      "# Show the whole color range\n",
      "for s in station_list:\n",
      "    if \"data\" in s:\n",
      "        years = s[\"data\"].keys()\n",
      "        xx = []\n",
      "        yx = []\n",
      "        for y in years:    \n",
      "            xx.append(int(y))\n",
      "            val = s[\"data\"][y][\"max\"]\n",
      "            yx.append(val)    \n",
      "        ppl.scatter(ax, xx, yx,alpha=0.8,edgecolor='black',linewidth=0.15 ,label=str(s[\"station_num\"]))\n",
      "\n",
      "\n",
      "ppl.legend(ax, loc='right', ncol=1)\n",
      "\n",
      "ax.set_title('`scatter` of waterlevel values')\n",
      "fig.set_size_inches(14,8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* plot time series of station values"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* create dict of station,year,max val"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* waves and currents and different notebook"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* work on getting the rest of the ngdc data points on to the map/analysed"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* two objects for obs and model data for ease of access"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Extreme Value Analysis:"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "First read in data (water levels from stations.json) * temp station yearly max data source"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename = 'stations.json'\n",
      "with open(filename) as data_file:    \n",
      "    data = json.load(data_file)\n",
      "    \n",
      "# Arbitrarily grab a station\n",
      "station = 'station-8449130'\n",
      "annual_max_levels = []\n",
      "for years, values in data[station].iteritems():\n",
      "    # Just grab the fields that contain data\n",
      "    try:\n",
      "        float(years)\n",
      "    except ValueError:\n",
      "        continue\n",
      "    annual_max_levels.append(values['max'])\n",
      "    #print years, values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "[Errno 2] No such file or directory: 'stations.json'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-22-6faa7b055600>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'stations.json'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Arbitrarily grab a station\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'stations.json'"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(12,6))\n",
      "axes = fig.add_axes([0.1, 0.1, 0.8, 0.8]) # left, bottom, width, height (range 0 to 1)\n",
      "axes.plot(annual_max_levels)\n",
      "axes.set_title('Nantucket Annual Maximum Sea Level')\n",
      "axes.set_ylabel('water level (m)')\n",
      "axes.set_xlabel('num years')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Fit data to GEV distribution"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sea_levels_gev_pdf(x):\n",
      "    return genextreme.pdf(x, xi, loc=mu, scale=sigma)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mle = genextreme.fit(sorted(annual_max_levels), 0)\n",
      "mu = mle[1]\n",
      "sigma = mle[2]\n",
      "xi = mle[0]\n",
      "print \"The mean, sigma, and shape parameters are %s, %s, and %s, resp.\" % (mu, sigma, xi)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Probability Density Plot"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.linspace(2, 7, num=100)\n",
      "y = [sea_levels_gev_pdf(z) for z in x]\n",
      "\n",
      "fig = plt.figure(figsize=(12,6))\n",
      "axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
      "axes.set_title(\"Probability Density & Normalized Histogram\")\n",
      "axes.set_xlabel(\"Nantucket Annual Maximum Sea Level (m)\")\n",
      "axes.plot(x, y, color='Red')\n",
      "axes.hist(annual_max_levels, bins=arange(2,7,0.5), normed=1, color='Yellow')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Return Value Plot"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(12,6))\n",
      "axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
      "T=np.r_[1:500]\n",
      "sT = genextreme.isf(1./T, 0, mu, sigma)\n",
      "axes.semilogx(T,sT), hold\n",
      "N=np.r_[1:len(annual_max_levels)+1]; \n",
      "Nmax=max(N);\n",
      "axes.plot(Nmax/N, sorted(annual_max_levels)[::-1],'.')\n",
      "axes.set_title('Return values in the GEV distribution')\n",
      "axes.set_xlabel('Return period')\n",
      "axes.set_ylabel('Return value') \n",
      "axes.grid(True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Compute Confidence Intervals"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}