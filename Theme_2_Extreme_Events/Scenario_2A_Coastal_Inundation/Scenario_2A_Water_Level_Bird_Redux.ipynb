{
 "metadata": {
  "name": "",
  "signature": "sha256:57e558f6a0ceb43d8b9b3052d41200a8b8da4e61365f5e1a6b7367309ecc1139"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "># IOOS System Test: [Extreme Events Theme:](https://github.com/ioos/system-test/wiki/Development-of-Test-Themes#theme-2-extreme-events) Inundation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Can we estimate the return period of a water level by comparing modeled and/or observed water levels with NOAA exceedance probability plots?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "import required libraries"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "from pylab import *\n",
      "import sys\n",
      "import csv\n",
      "import json\n",
      "from scipy.stats import genextreme\n",
      "import scipy.stats as ss\n",
      "import numpy as np\n",
      "\n",
      "from owslib.csw import CatalogueServiceWeb\n",
      "from owslib import fes\n",
      "import random\n",
      "import netCDF4\n",
      "import pandas as pd\n",
      "import datetime as dt\n",
      "from pyoos.collectors.coops.coops_sos import CoopsSos\n",
      "import cStringIO\n",
      "import iris\n",
      "import urllib2\n",
      "import parser\n",
      "from lxml import etree       #TODO suggest using bs4 instead for ease of access to XML objects\n",
      "\n",
      "#generated for csw interface\n",
      "#from date_range_formatter import dateRange  #date formatter (R.Signell)\n",
      "import requests              #required for the processing of requests\n",
      "from utilities import * \n",
      "\n",
      "from IPython.display import HTML\n",
      "import folium #required for leaflet mapping\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "some functions from [Rich Signell Notebook](http://nbviewer.ipython.org/github/rsignell-usgs/notebook/blob/fef9438303b49a923024892db1ef3115e34d8271/CSW/IOOS_inundation.ipynb)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Speficy Temporal and Spatial conditions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#bounding box of interest,[bottom right[lat,lon], top left[lat,lon]]\n",
      "bounding_box_type = \"box\" \n",
      "bounding_box = [[-70.94,40.67],[-68.94,41.5]]\n",
      "\n",
      "#temporal range\n",
      "start_date = dt.datetime(1991,5,1).strftime('%Y-%m-%d %H:00')\n",
      "end_date = dt.datetime(2014,5,7).strftime('%Y-%m-%d %H:00')\n",
      "time_date_range = [start_date,end_date]  #start_date_end_date\n",
      "\n",
      "print start_date,'to',end_date"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1991-05-01 00:00 to 2014-05-07 00:00\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "name_list=['water_surface_height_above_reference_datum',\n",
      "    'sea_surface_height_above_geoid','sea_surface_elevation',\n",
      "    'sea_surface_height_above_reference_ellipsoid','sea_surface_height_above_sea_level',\n",
      "    'sea_surface_height','water level']\n",
      "\n",
      "sos_name = 'water_surface_height_above_reference_datum'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "endpoint = 'http://www.ngdc.noaa.gov/geoportal/csw' # NGDC Geoportal\n",
      "csw = CatalogueServiceWeb(endpoint,timeout=60)\n",
      "\n",
      "for oper in csw.operations:\n",
      "    if oper.name == 'GetRecords':\n",
      "        print '\\nISO Queryables:\\n',oper.constraints['SupportedISOQueryables']['values']\n",
      "        #pass\n",
      "        \n",
      "#put the names in a dict for ease of access \n",
      "data_dict = {}\n",
      "data_dict[\"water\"] = {\"names\":['water_surface_height_above_reference_datum',\n",
      "    'sea_surface_height_above_geoid','sea_surface_elevation',\n",
      "    'sea_surface_height_above_reference_ellipsoid','sea_surface_height_above_sea_level',\n",
      "    'sea_surface_height','water level'], \"sos_name\":['water_surface_height_above_reference_datum']}      "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "ISO Queryables:\n",
        "['apiso:Subject', 'apiso:Title', 'apiso:Abstract', 'apiso:AnyText', 'apiso:Format', 'apiso:Identifier', 'apiso:Modified', 'apiso:Type', 'apiso:BoundingBox', 'apiso:CRS.Authority', 'apiso:CRS.ID', 'apiso:CRS.Version', 'apiso:RevisionDate', 'apiso:AlternateTitle', 'apiso:CreationDate', 'apiso:PublicationDate', 'apiso:OrganizationName', 'apiso:HasSecurityConstraints', 'apiso:Language', 'apiso:ResourceIdentifier', 'apiso:ParentIdentifier', 'apiso:KeywordType', 'apiso:TopicCategory', 'apiso:ResourceLanguage', 'apiso:GeographicDescriptionCode', 'apiso:Denominator', 'apiso:DistanceValue', 'apiso:DistanceUOM', 'apiso:TempExtent_begin', 'apiso:TempExtent_end', 'apiso:ServiceType', 'apiso:ServiceTypeVersion', 'apiso:Operation', 'apiso:OperatesOn', 'apiso:OperatesOnIdentifier', 'apiso:OperatesOnName', 'apiso:CouplingType']\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dateRange(start_date='1900-01-01',stop_date='2100-01-01',constraint='overlaps'):\n",
      "    if constraint == 'overlaps':\n",
      "        start = fes.PropertyIsLessThanOrEqualTo(propertyname='apiso:TempExtent_begin', literal=stop_date)\n",
      "        stop = fes.PropertyIsGreaterThanOrEqualTo(propertyname='apiso:TempExtent_end', literal=start_date)\n",
      "    elif constraint == 'within':\n",
      "        start = fes.PropertyIsGreaterThanOrEqualTo(propertyname='apiso:TempExtent_begin', literal=start_date)\n",
      "        stop = fes.PropertyIsLessThanOrEqualTo(propertyname='apiso:TempExtent_end', literal=stop_date)\n",
      "    return start,stop"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# convert User Input into FES filters\n",
      "start,stop = dateRange(start_date,end_date)\n",
      "box = []\n",
      "box.append(bounding_box[0][0])\n",
      "box.append(bounding_box[0][1])\n",
      "box.append(bounding_box[1][0])\n",
      "box.append(bounding_box[1][1])\n",
      "bbox = fes.BBox(box)\n",
      "\n",
      "or_filt = fes.Or([fes.PropertyIsLike(propertyname='apiso:AnyText',literal=('*%s*' % val),\n",
      "                    escapeChar='\\\\',wildCard='*',singleChar='?') for val in name_list])\n",
      "val = 'Averages'\n",
      "not_filt = fes.Not([fes.PropertyIsLike(propertyname='apiso:AnyText',literal=('*%s*' % val),\n",
      "                        escapeChar='\\\\',wildCard='*',singleChar='?')])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filter_list = [fes.And([ bbox, start, stop, or_filt, not_filt]) ]\n",
      "# connect to CSW, explore it's properties\n",
      "# try request using multiple filters \"and\" syntax: [[filter1,filter2]]\n",
      "csw.getrecords2(constraints=filter_list,maxrecords=1000,esn='full')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def service_urls(records,service_string='urn:x-esri:specification:ServiceType:odp:url'):\n",
      "    \"\"\"\n",
      "    extract service_urls of a specific type (DAP, SOS) from records\n",
      "    \"\"\"\n",
      "    urls=[]\n",
      "    for key,rec in records.iteritems():\n",
      "        #create a generator object, and iterate through it until the match is found\n",
      "        #if not found, gets the default value (here \"none\")\n",
      "        url = next((d['url'] for d in rec.references if d['scheme'] == service_string), None)\n",
      "        if url is not None:\n",
      "            urls.append(url)\n",
      "    return urls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print records that are available\n",
      "print \"number of datasets available: \",len(csw.records.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "number of datasets available:  95\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Print all the records (should you want too)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print \"\\n\".join(csw.records)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Dap URLS"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dap_urls = service_urls(csw.records,service_string='urn:x-esri:specification:ServiceType:odp:url')\n",
      "#remove duplicates and organize\n",
      "dap_urls = sorted(set(dap_urls))\n",
      "print \"Total DAP:\",len(dap_urls)\n",
      "#print the first 5...\n",
      "print \"\\n\".join(dap_urls[0:5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total DAP: 20\n",
        "http://colossus.dl.stevens-tech.edu/thredds/dodsC/latest/Complete_gcmplt.nc\n",
        "http://comt.sura.org/thredds/dodsC/data/comt_1_archive/inundation_tropical/VIMS_SELFE/Hurricane_Ike_2D_final_run_wave_only\n",
        "http://comt.sura.org/thredds/dodsC/data/comt_1_archive/inundation_tropical/VIMS_SELFE/Hurricane_Ike_2D_final_run_with_waves\n",
        "http://comt.sura.org/thredds/dodsC/data/comt_1_archive/inundation_tropical/VIMS_SELFE/Hurricane_Ike_2D_final_run_without_waves\n",
        "http://comt.sura.org/thredds/dodsC/data/comt_1_archive/inundation_tropical/VIMS_SELFE/Hurricane_Ike_3D_final_run_with_waves\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "SOS URLs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sos_urls = service_urls(csw.records,service_string='urn:x-esri:specification:ServiceType:sos:url')\n",
      "#remove duplicates and organize\n",
      "sos_urls = sorted(set(sos_urls))\n",
      "print \"Total SOS:\",len(sos_urls)\n",
      "print \"\\n\".join(sos_urls)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total SOS: 1\n",
        "http://opendap.co-ops.nos.noaa.gov/ioos-dif-sos/SOS?service=SOS&request=GetCapabilities\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### SOS Requirements"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#use the get caps to get station start and get time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start_time = dt.datetime.strptime(start_date,'%Y-%m-%d %H:%M')\n",
      "end_time = dt.datetime.strptime(end_date,'%Y-%m-%d %H:%M')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iso_start = start_time.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
      "iso_end = end_time.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
      "\n",
      "collector = CoopsSos()\n",
      "collector.set_datum('NAVD')\n",
      "collector.server.identification.title\n",
      "collector.start_time = start_time\n",
      "collector.end_time = end_time\n",
      "collector.variables = [data_dict[\"water\"][\"sos_name\"]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Date: \",iso_start,\" to \", iso_end\n",
      "box_str=','.join(str(e) for e in box)\n",
      "print \"Lat/Lon Box: \",box_str\n",
      "#grab the sos url and use it for the service\n",
      "url=(sos_urls[0].split(\"?\")[0]+'?'\n",
      "     'service=SOS&request=GetObservation&version=1.0.0&'\n",
      "     'observedProperty=%s&offering=urn:ioos:network:NOAA.NOS.CO-OPS:WaterLevelActive&'\n",
      "     'featureOfInterest=BBOX:%s&responseFormat=text/tab-separated-values&eventTime=%s') % (sos_name,box_str,iso_end)\n",
      "\n",
      "r = requests.get(url)\n",
      "data = r.text\n",
      "#get the headers for the cols\n",
      "data = data.split(\"\\n\")\n",
      "headers =  data[0]\n",
      "station_list_dict = dict()\n",
      "#parse the headers so i can create a dict\n",
      "c = 0\n",
      "for h in headers.split(\"\\t\"):\n",
      "    field = h.split(\":\")[0].split(\" \")[0]\n",
      "    station_list_dict[field] = {\"id\":c}\n",
      "    c+=1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Date:  1991-05-01T00:00:00Z  to  2014-05-07T00:00:00Z\n",
        "Lat/Lon Box:  -70.94,40.67,-68.94,41.5\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_coops_longName(sta):\n",
      "    \"\"\"\n",
      "    get longName for specific station from COOPS SOS using DescribeSensor request\n",
      "    \"\"\"\n",
      "    url=(sos_urls[0].split(\"?\")[0]+'?service=SOS&'\n",
      "        'request=DescribeSensor&version=1.0.0&outputFormat=text/xml;subtype=\"sensorML/1.0.1\"&'\n",
      "        'procedure=%s') % sta\n",
      "    tree = etree.parse(urllib2.urlopen(url))\n",
      "    root = tree.getroot()\n",
      "    longName=root.xpath(\"//sml:identifier[@name='longName']/sml:Term/sml:value/text()\", namespaces={'sml':\"http://www.opengis.net/sensorML/1.0.1\"})\n",
      "    return longName"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#finds the max value given a json object\n",
      "def findMaxVal(data):\n",
      "    dates_array = []\n",
      "    vals_array = []\n",
      "    for x in data:\n",
      "        dates_array.append(str(x[\"t\"]))\n",
      "        vals_array.append(x[\"v\"])\n",
      "    \n",
      "    p = np.array(vals_array,dtype=np.float)\n",
      "    x = np.arange(len(p))\n",
      "    max_val = np.amax(p)\n",
      "    max_idx = np.argmax(p)\n",
      "    return (max_val,len(p),dates_array[max_idx])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def coops2data(collector,station_id,sos_name):\n",
      "    collector.features = [station_id]\n",
      "    collector.variables = [sos_name]\n",
      "    station_data = dict()\n",
      "    #loop through the years and get the data needed\n",
      "    for year_station in range(int(collector.start_time.year),collector.end_time.year+1):      \n",
      "        link = \"http://tidesandcurrents.noaa.gov/api/datagetter?product=\"+sos_name+\"&application=NOS.COOPS.TAC.WL&\"\n",
      "        date1 = \"begin_date=\"+str(year_station)+\"0101\"\n",
      "        date2 = \"&end_date=\"+str(year_station)+\"1231\"\n",
      "        datum = \"&datum=MHHW\"\n",
      "        units = \"&units=metric\"\n",
      "        station_request = \"&station=\"+station_id+\"&time_zone=GMT&units=english&format=json\"\n",
      "        http_request = link+date1+date2+units+datum+station_request\n",
      "        #print http_request\n",
      "        d_r = requests.get(http_request,timeout=20)\n",
      "        if \"Great Lake station\" in d_r.text:\n",
      "            pass\n",
      "        else:\n",
      "            key_list =  d_r.json().keys()\n",
      "            if \"data\" in key_list:\n",
      "                data = d_r.json()['data']\n",
      "                max_value,num_samples,date_string = findMaxVal(data)\n",
      "                station_data[str(year_station)] =  {\"max\":max_value,\"num_samples\":num_samples,\"date_string\":date_string,\"raw\":data}\n",
      "                #print \"\\tyear:\",year_station,\" MaxValue:\",max_value\n",
      "    return station_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create dict of stations\n",
      "station_list = []\n",
      "for i in range(1,len(data)):\n",
      "    station_info = data[i].split(\"\\t\")\n",
      "    station = dict()\n",
      "    for field in station_list_dict.keys():        \n",
      "        col = station_list_dict[field][\"id\"]\n",
      "        if col < len(station_info):\n",
      "            station[field] = station_info[col]     \n",
      "    station_list.append(station)        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Embeds the HTML source of the map directly into the IPython notebook.\n",
      "def inline_map(map):   \n",
      "    map._build_map()\n",
      "    return HTML('<iframe srcdoc=\"{srcdoc}\" style=\"width: 100%; height: 500px; border: none\"></iframe>'.format(srcdoc=map.HTML.replace('\"', '&quot;')))\n",
      "\n",
      "\n",
      "#print bounding_box[0]\n",
      "map = folium.Map(location=[bounding_box[0][1], bounding_box[0][0]], zoom_start=6)\n",
      "\n",
      "station_yearly_max = []\n",
      "for s in station_list:\n",
      "    #get the long name\n",
      "    s[\"long_name\"] =get_coops_longName(s['station_id'])\n",
      "    #get the data\n",
      "    station_num = str(s['station_id']).split(':')[-1]\n",
      "    s[\"station_num\"] = station_num\n",
      "    #this is different than sos name, hourly height is hourly water level\n",
      "    raw_data = coops2data(collector,station_num,\"hourly_height\")    \n",
      "    s[\"data\"] = raw_data\n",
      "    if \"latitude\" in s:\n",
      "        popup_string = '<b>Station:</b><br>'+str(s['station_id']) + \"<br><b>Long Name:</b><br>\"+str(s[\"long_name\"])\n",
      "        map.simple_marker([s[\"latitude\"],s[\"longitude\"]],popup=popup_string)\n",
      "   \n",
      "    #break after the first one    \n",
      "    break\n",
      "# Create the map and add the bounding box line\n",
      "map.line(get_coordinates(bounding_box,bounding_box_type), line_color='#FF0000', line_weight=5)\n",
      "\n",
      "inline_map(map)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<iframe srcdoc=\"<!DOCTYPE html>\n",
        "<head>\n",
        "   <meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; />\n",
        "   <link rel=&quot;stylesheet&quot; href=&quot;http://cdn.leafletjs.com/leaflet-0.7.2/leaflet.css&quot; />\n",
        "   <script src=&quot;http://cdn.leafletjs.com/leaflet-0.7.2/leaflet.js&quot;></script>\n",
        "\n",
        "   \n",
        "   \n",
        "   \n",
        "   \n",
        "\n",
        "\n",
        "   <style>\n",
        "\n",
        "      #map {\n",
        "        position:absolute;\n",
        "        top:0;\n",
        "        bottom:0;\n",
        "        right:0;\n",
        "        left:0;\n",
        "      }\n",
        "\n",
        "   </style>\n",
        "</head>\n",
        "\n",
        "<body>\n",
        "\n",
        "   <div class=&quot;folium-map&quot; id=&quot;folium_98c442f94ee147dcaa2724cbfe84d718&quot; style=&quot;width: 960px; height: 500px&quot;></div>\n",
        "\n",
        "   <script>\n",
        "\n",
        "      \n",
        "\n",
        "      var map = L.map('folium_98c442f94ee147dcaa2724cbfe84d718').setView([40.67, -70.94], 6);\n",
        "\n",
        "      L.tileLayer('http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', {\n",
        "          maxZoom: 18,\n",
        "          attribution: 'Map data (c) <a href=&quot;http://openstreetmap.org&quot;>OpenStreetMap</a> contributors'\n",
        "      }).addTo(map);\n",
        "\n",
        "      \n",
        "      var marker_1 = L.marker([41.2850, -70.0967]);\n",
        "      marker_1.bindPopup(&quot;<b>Station:</b><br>urn:ioos:station:NOAA.NOS.CO-OPS:8449130<br><b>Long Name:</b><br>['Nantucket Island, MA']&quot;);\n",
        "      map.addLayer(marker_1)\n",
        "      \n",
        "\n",
        "      \n",
        "      var latLngs = [ [40.67, -70.94],  [40.67, -68.94],  [41.5, -68.94],  [41.5, -70.94],  [40.67, -70.94], ];\n",
        "var line_1 = L.polyline(latLngs,{\n",
        "color: '#FF0000',\n",
        "weight: 5,\n",
        "\n",
        "});\n",
        "      map.addLayer(line_1);\n",
        "      \n",
        "\n",
        "      \n",
        "\n",
        "      \n",
        "\n",
        "   </script>\n",
        "\n",
        "</body>\" style=\"width: 100%; height: 500px; border: none\"></iframe>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "<IPython.core.display.HTML at 0x5e55a10>"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import prettyplotlib as ppl\n",
      "\n",
      "# Set the random seed for consistency\n",
      "np.random.seed(12)\n",
      "\n",
      "fig, ax = plt.subplots(1)\n",
      "\n",
      "# Show the whole color range\n",
      "for s in station_list:\n",
      "    if \"data\" in s:\n",
      "        years = s[\"data\"].keys()\n",
      "        xx = []\n",
      "        yx = []\n",
      "        for y in years:    \n",
      "            xx.append(int(y))\n",
      "            val = s[\"data\"][y][\"max\"]\n",
      "            yx.append(val)  \n",
      "        \n",
      "        #ax.scatter(xx,yx,marker='o')\n",
      "        #ppl.scatter(ax, xx, yx, alpha=0.8, edgecolor='black', linewidth=0.15, label=str(s[\"station_num\"]))\n",
      "        ax.scatter(xx, yx, label=str(s[\"station_num\"]))\n",
      "\n",
      "        #ppl.legend(ax, loc='right', ncol=1)\n",
      "        legend = ax.legend(loc='best')\n",
      "        \n",
      "        # The frame is matplotlib.patches.Rectangle instance surrounding the legend.\n",
      "        frame  = legend.get_frame()\n",
      "        \n",
      "        title = s[\"long_name\"][0] + ' water level'\n",
      "        ax.set_title(title)\n",
      "        ax.set_xlabel('Year')\n",
      "        ax.set_ylabel('water level (m)')\n",
      "        break\n",
      "\n",
      "fig.set_size_inches(14,8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Extreme Value Analysis:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "annual_max_levels = yx\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Fit data to GEV distribution"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sea_levels_gev_pdf(x):\n",
      "    return genextreme.pdf(x, xi, loc=mu, scale=sigma)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mle = genextreme.fit(sorted(annual_max_levels), 0)\n",
      "mu = mle[1]\n",
      "sigma = mle[2]\n",
      "xi = mle[0]\n",
      "print \"The mean, sigma, and shape parameters are %s, %s, and %s, resp.\" % (mu, sigma, xi)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The mean, sigma, and shape parameters are 0.592247615711, 0.16293628494, and 0.00118719119031, resp.\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Probability Density Plot"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "min_x = min(annual_max_levels)-0.5\n",
      "max_x = max(annual_max_levels)+0.5\n",
      "x = np.linspace(min_x, max_x, num=100)\n",
      "y = [sea_levels_gev_pdf(z) for z in x]\n",
      "\n",
      "fig = plt.figure(figsize=(12,6))\n",
      "axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
      "xlabel = (s[\"long_name\"][0] + \" - Annual max water level (m)\")\n",
      "axes.set_title(\"Probability Density & Normalized Histogram\")\n",
      "axes.set_xlabel(xlabel)\n",
      "axes.plot(x, y, color='Red')\n",
      "axes.hist(annual_max_levels, bins=arange(min_x, max_x, abs((max_x-min_x)/10)), normed=1, color='Yellow')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "(array([ 0.        ,  0.        ,  0.8604371 ,  1.93598348,  1.50576493,\n",
        "         0.64532783,  0.        ,  0.21510928,  0.        ]),\n",
        " array([-0.125 ,  0.0687,  0.2624,  0.4561,  0.6498,  0.8435,  1.0372,\n",
        "         1.2309,  1.4246,  1.6183]),\n",
        " <a list of 9 Patch objects>)"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Return Value Plot"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This plot should match NOAA's [Annual Exceedance Probability Curves for station 8449130](http://tidesandcurrents.noaa.gov/est/curves.shtml?stnid=8449130)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(20,6))\n",
      "axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
      "T=np.r_[1:500]\n",
      "sT = genextreme.isf(1./T, 0, mu, sigma)\n",
      "axes.semilogx(T, sT, 'r'), hold\n",
      "N=np.r_[1:len(annual_max_levels)+1]; \n",
      "Nmax=max(N);\n",
      "axes.plot(Nmax/N, sorted(annual_max_levels)[::-1], 'bo')\n",
      "title = s[\"long_name\"][0] \n",
      "axes.set_title(title)\n",
      "axes.set_xlabel('Return Period (yrs)')\n",
      "axes.set_ylabel('Meters above MHHW') \n",
      "axes.grid(True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This plot does not match exactly. NOAA's curves were calculated using the Extremes Toolkit software package in R whereas this notebook uses scipy. There is a python package based on the Extremes Toolkit called pywafo but this is experimental and isn't building properly on Mac OS X"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    }
   ],
   "metadata": {}
  }
 ]
}